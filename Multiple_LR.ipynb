{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiple LR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Linear Regression Example               \n",
        "Multiple Linear regression implementation with TensorFlow v2 library.     \n",
        "\n",
        "This example is using a low-level approach to better understand all mechanics behind the training process.\n",
        "\n",
        "Original Author: Aymeric Damien        \n",
        "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
        "\n",
        "The original notebook has code for simple linear regression, I changed that to reflect my learning of `Multiple Linear Regression`."
      ],
      "metadata": {
        "id": "STd4kpt20c6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "rng = np.random"
      ],
      "metadata": {
        "id": "WY77ZSA_5G-p"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.01\n",
        "TRAIN_STEP = 1000\n",
        "DISPLAY_STEP = 50\n",
        "\n",
        "X = np.array([[3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
        "              7.042,10.791,5.313,7.997,5.654,9.27,3.1],[3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
        "              7.042,10.791,5.313,7.997,5.654,9.27,3.1],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]])\n",
        "Y = np.array([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
        "              7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
        "\n",
        "W = tf.Variable(rng.randn(X.shape[0],1), name=\"weight\")"
      ],
      "metadata": {
        "id": "oNwAqD825dt7"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_regression(x):\n",
        "  return x.T @ W"
      ],
      "metadata": {
        "id": "YaRipYuHAoC4"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_square(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true.reshape(-1,1)))"
      ],
      "metadata": {
        "id": "UUisoSLHAodN"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.optimizers.SGD(LR)"
      ],
      "metadata": {
        "id": "78Vo9tpCA0bN"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_optimization():\n",
        "\n",
        "  with tf.GradientTape() as g:\n",
        "    pred = linear_regression(X)\n",
        "    loss = mean_square(pred, Y)\n",
        "\n",
        "  # Computer gradients\n",
        "  gradients = g.gradient(loss, [W])\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, [W]))"
      ],
      "metadata": {
        "id": "l-BmNMQFA11V"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(1, 2500 + 1):\n",
        "    # Run the optimization to update W and b values.\n",
        "    run_optimization()\n",
        "    \n",
        "    if step % DISPLAY_STEP == 0:\n",
        "        pred = linear_regression(X)\n",
        "        loss = mean_square(pred, Y)\n",
        "        print(\"step: %i, loss: %f\" % (step, loss))"
      ],
      "metadata": {
        "id": "aUpJw8sgBhZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25dc7ad5-9559-463e-86e9-1e4c9e9fb7d8"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 50, loss: 0.101786\n",
            "step: 100, loss: 0.079632\n",
            "step: 150, loss: 0.062300\n",
            "step: 200, loss: 0.048741\n",
            "step: 250, loss: 0.038132\n",
            "step: 300, loss: 0.029833\n",
            "step: 350, loss: 0.023339\n",
            "step: 400, loss: 0.018260\n",
            "step: 450, loss: 0.014285\n",
            "step: 500, loss: 0.011176\n",
            "step: 550, loss: 0.008744\n",
            "step: 600, loss: 0.006841\n",
            "step: 650, loss: 0.005352\n",
            "step: 700, loss: 0.004187\n",
            "step: 750, loss: 0.003276\n",
            "step: 800, loss: 0.002563\n",
            "step: 850, loss: 0.002005\n",
            "step: 900, loss: 0.001569\n",
            "step: 950, loss: 0.001227\n",
            "step: 1000, loss: 0.000960\n",
            "step: 1050, loss: 0.000751\n",
            "step: 1100, loss: 0.000588\n",
            "step: 1150, loss: 0.000460\n",
            "step: 1200, loss: 0.000360\n",
            "step: 1250, loss: 0.000281\n",
            "step: 1300, loss: 0.000220\n",
            "step: 1350, loss: 0.000172\n",
            "step: 1400, loss: 0.000135\n",
            "step: 1450, loss: 0.000105\n",
            "step: 1500, loss: 0.000082\n",
            "step: 1550, loss: 0.000065\n",
            "step: 1600, loss: 0.000050\n",
            "step: 1650, loss: 0.000039\n",
            "step: 1700, loss: 0.000031\n",
            "step: 1750, loss: 0.000024\n",
            "step: 1800, loss: 0.000019\n",
            "step: 1850, loss: 0.000015\n",
            "step: 1900, loss: 0.000012\n",
            "step: 1950, loss: 0.000009\n",
            "step: 2000, loss: 0.000007\n",
            "step: 2050, loss: 0.000006\n",
            "step: 2100, loss: 0.000004\n",
            "step: 2150, loss: 0.000003\n",
            "step: 2200, loss: 0.000003\n",
            "step: 2250, loss: 0.000002\n",
            "step: 2300, loss: 0.000002\n",
            "step: 2350, loss: 0.000001\n",
            "step: 2400, loss: 0.000001\n",
            "step: 2450, loss: 0.000001\n",
            "step: 2500, loss: 0.000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.T @ W"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOseS-LP3oAN",
        "outputId": "e57c7a90-e1f4-468c-c8b6-677111f691d3"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(17, 1), dtype=float64, numpy=\n",
              "array([[ 3.30118656],\n",
              "       [ 4.40084301],\n",
              "       [ 5.50049946],\n",
              "       [ 6.71012155],\n",
              "       [ 6.93005284],\n",
              "       [ 4.16891546],\n",
              "       [ 9.77816305],\n",
              "       [ 6.18228646],\n",
              "       [ 7.58984671],\n",
              "       [ 2.16854041],\n",
              "       [ 7.04201786],\n",
              "       [10.78984699],\n",
              "       [ 5.31355786],\n",
              "       [ 7.9967196 ],\n",
              "       [ 5.65445136],\n",
              "       [ 9.26932202],\n",
              "       [ 3.10124902]])>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.reshape(-1,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lkHaUWvwZU2",
        "outputId": "9b324655-5107-4d4d-a551-67190a1c0d6d"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.3  ],\n",
              "       [ 4.4  ],\n",
              "       [ 5.5  ],\n",
              "       [ 6.71 ],\n",
              "       [ 6.93 ],\n",
              "       [ 4.168],\n",
              "       [ 9.779],\n",
              "       [ 6.182],\n",
              "       [ 7.59 ],\n",
              "       [ 2.167],\n",
              "       [ 7.042],\n",
              "       [10.791],\n",
              "       [ 5.313],\n",
              "       [ 7.997],\n",
              "       [ 5.654],\n",
              "       [ 9.27 ],\n",
              "       [ 3.1  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    }
  ]
}